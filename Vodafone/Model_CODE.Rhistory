# завантажуємо попередньо оброблений у Python файл даних "hackaton_A_full.csv" як "data.full" використовуючи RKWard: Файл -> Імпортувати -> Import format -> Import Text/CSV data
# а також файл із цільовою змінною "hackaton_target.csv" (змінні у фактори не конвертуємо)

# завантажуємо з робочого каталогу функцію для побудови кривої ROC та обчислення показника AUC
source("roc.auc.R")

# підключаємо необхідні бібліотеки
library(ROCR)
library(MASS)

# попередня обробка даних
data.full<-data.full[-c(19,20)] # дані по двох змінних було втрачено при вивантаженні з Amazon, їх видаляємо
data.full<-merge(data.full,target,by="hash_number_A") # зливаємо тренувальні дані з цільовою змінною (target)
# вилучаємо зайву для аналізу характеристику -- hash_number_A
data.full_log<-data.full[-1]
# логарифмуємо деякі features для наближення їх розподілу до нормального
data.full_log$cost<-log(data.full$cost+1)
data.full_log$cost_refill<-log(data.full$cost_refill+1)
data.full_log$expense<-log(data.full$expense+1)
data.full_log$income_minutes<-log(data.full$income_minutes+1)
data.full_log$outcome_minutes<-log(data.full$outcome_minutes+1)
data.full_log$voda_minutes<-log(data.full$voda_minutes+1)
data.full_log$nonvoda_minutes<-log(data.full$nonvoda_minutes+1)
data.full_log$nonvoda_sms<-log(data.full$nonvoda_sms+1)
data.full_log$voda_sms<-log(data.full$voda_sms+1)
data.full_log$inet_mb<-log(data.full$inet_mb+1)

# формуємо train/validate sets 
set.seed(862)
train_index4a<-sample(7990,6392)
train_full4a<-data.full_log[train_index4a,]
valid_full4a<-data.full_log[-train_index4a,]

# будуємо модель логістичної регресії
model_logreg4a<-glm(target~.,data=train_full4a,family=binomial())
pred_logreg4a<-predict(model_logreg4a,valid_full4a[-19],type="response")
auc_logreg4a<-roc.auc(pred_logreg4a,valid_full4a$target)

# покращуємо модель, покроково видаляючи по одній змінній, поки показник AIC не перестане зменшуватися
model_logreg4b<-stepAIC(model_logreg4a,direction="backward")
pred_logreg4b<-predict(model_logreg4b,valid_full4a[-19],type="response")
auc_logreg4b<-roc.auc(pred_logreg4b,valid_full4a$target)

# завантажуємо попередньо оброблений у Python файл даних "hackaton_A_test_flag_1.csv" як "data.org" використовуючи RKWard: Файл -> Імпортувати -> Import format -> Import Text/CSV data

# попередня обробка даних
data.org<-data.org[-c(19,20)]
data.org<-merge(data.org,target,by="hash_number_A")
data.org$cost<-log(data.org$cost+1)
data.org$cost_refill<-log(data.org$cost_refill+1)
data.org$expense<-log(data.org$expense+1)
data.org$income_minutes<-log(data.org$income_minutes+1)
data.org$outcome_minutes<-log(data.org$outcome_minutes+1)
data.org$voda_minutes<-log(data.org$voda_minutes+1)
data.org$nonvoda_minutes<-log(data.org$nonvoda_minutes+1)
data.org$nonvoda_sms<-log(data.org$nonvoda_sms+1)
data.org$voda_sms<-log(data.org$voda_sms+1)
data.org$inet_mb<-log(data.org$inet_mb+1)

# застосовуємо модель логістичної регресії -- обчислюємо ймовірності відтоку клієнтів
data.org$target<-predict(model_logreg4b,data.org[-c(1,20)],type="response")
data.org$target<-round(data.org$target,4)
write.csv(data.org[c(1,20)],"team5_solution_LogReg.csv",row.names=FALSE)

# будуємо іншу модель -- Random Forests
library(randomForest)
set.seed(862)
train_full4a<-factor(train_full4a)
valid_full4a<-factor(valid_full4a)
model_RF8<-randomForest(target~.,data=train_full4a,mtry=8)
pred_RF8<-predict(model_RF8,valid_full4a[-19],type="prob")

# застосовуємо модель Random Forests
data.org$target<-predict(model_RF8,data.org[-c(1,20)],type="prob")[,2]
data.org$target<-round(data.org$target,4)
write.csv(data.org[c(1,20)],"team5_solution_RandFor.csv",row.names=FALSE)
